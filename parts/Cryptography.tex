% !TeX root = ./Thesis.tex
\section{Cryptography}

Cryptography is a field of mathematics that uses computationally difficult problems to obfuscate, hide, split and verify data. Starting in the ancient times with the famous Caesar cipher, which relied on shifting the letters in a message in coordination to an alphabet, there are multiple cryptographic protocols today for a variety of use cases, which are used in both public and private messaging. As mentioned earlier, while the familiar connotation of cryptography as a word brings secrecy and secure communications into mind, it can also be used to verify data, and to prove that something has happened. I will go over cryptography subjects that are relevant to the Proof of Latency protocol in this chapter, like groups of unknown order, RSA and cryptographic proofs. 

Modern cryptography is based on relatively few mathematical fundamentals. The most dominant one during the age of computers has been prime numbers with modular multiplication, but elliptic curve cryptography is used widely today because of its easy and less resource-intensive key generation method when compared to the prime number based RSA cryptosystem. They both use modular arithmetic in their operations.

Modular\footnote{Using the modulus operation; taking the remainder of a division. Useful in cryptography because it creates finite cyclical groups.} arithmetic with large numbers has a useful property that you can exchange encrypted data without the participants knowing each other's private keys, but requiring a computation that is theoretically almost impossible to break due to the prime factorization problem. These large numbers that are used as the modulo need to have unknown factorizations to create groups of unknown order, that are paramount to cryptographic systems that rely on the factorization problem for their safety. The order of a group means the amount of elements in it. Cryptographic proofs need to be created with groups of unknown orders for them to be valid, as knowing the order of a group means that the modulo used in the cryptographic operations is so small that it has a known factorization, and the security of the factorization problem is broken.

\subsection{RSA}
RSA is named after it's discoverers â€“ Rivest, Shamir, Adleman. It is an asymmetric public-key cryptosystem, meaning that it is based on a keypair, in which one is a public and the other is a secret. The public key is used to encrypt, and the secret key is used to decrypt. Everyone who has the public key can encrypt data and that encrypted data is practically impossible to decrypt without the secret key. This works due to the fact that it is hard to factor the product of two large prime numbers. RSA has been the most widely used cryptosystem since its creation, and is easy to use in modern context by just increasing the size of the keys.

RSA is an arithmetic trick that creates a mathematical object called a trapdoor permutation. Trapdoor permutation is a function that transforms a number x to a number y in the same range, in a way that computing y from x is easy using the public key but computing x from y is practically impossible without knowing the private key. The private key is the trapdoor.~\cite{Aumasson2018-nh} RSA relies on the prime factorization problem and groups of unknown order for its security. RSA has played a big part in the development of cryptography, and even served as a motivation for the creation of verifiable delay functions, as it was used in the creation of time-lock puzzles closely related to VDFs.

At first, one must create a key pair to use RSA, which needs to be distributed between the involved peers to be used in encryption. This key generation process is quite resource intensive, and is rarely used in ephemeral contexts, unless you can skip the key generation process and use a publicly available modulo that is created by a trusted party. These types of key generation processes are called trusted setups, and they produce so-called toxic waste that needs to be discarded to preserve the key safety.

The company formed by the RSA algorithm's inventors, RSA Security LLC, published public RSA semiprimes\footnote{A product of two prime numbers} that are called RSA numbers as a part of the RSA factoring challenge from 1991 up until 2007 when the challenge ended.~\cite{RSA_Laboratories2013-zk} The challenge was ended because it had reached its purpose of forwarding science and understanding of common symmetric-key and public-key algorithms. Despite this, still under a half of the RSA numbers have been factored, and the largest of them might take hundreds if not even thousands of years to break even when given extraordinary hardware to do it with.

Given that the RSA numbers are said to have been created with a machine that was completely destroyed after their creation and the primes were never apparent to anyone, you need to trust the company's claims if you ever use these public challenge numbers. Fortunately, usually they are not used for encrypting large swathes of personal data, but in a more ephemeral context like Proof of Latency, which wouldn't cause a huge stir if the cryptosystem was broken and needed changing.

\subsection{Cryptographic Proofs and Their Soundness} % TODO: Proofs of knowledge? Not all proofs are dependant on the trapdoor nature of crypto, and they're not really dependant at that, rather creating the trapdoor nature rather than depending on it.
Cryptographic proofs are proofs that depend on the trapdoor nature of cryptographic functions. The most well-known proofs, which are not necessarily thought of as such, are cryptographic signatures. Given a public key, a computer in posession of its corresponding private key can produce a signature of any given data, implying together with the data that the computer has seen and processed the data without revealing the private key to the third party, retaining unique access to the identity that is the public key. These proofs are called proofs of knowledge.

Proofs can be private or public. A cryptographic proof can be categorized as public, if a verifier can gather all information required to verify the proof from the transcript of the proof itself, and verify the proof to be correct. Now, since classical cryptography is based on the fact that a computation is asymmetric --- being harder to compute the other way around, a cryptographic proof is still probabilistic in nature, and the security of it based not only on the algorithm but also the parameters used.

Proofs need to be tested for soundness to be called as such. Soundness means that a prover cannot make a verifier accept a false statement with reasonable probability. This means that a proof is dependent on context, the verifier. If a proof holds statistically, it's a proof. If it instead holds only computationally, it's instead called an argument.



\subsection{Commitment Schemes}
% TODO: Use cryptographically 'cool' values for the variables
Commitment schemes are a way to lock causality in a cryptographic protocol, an are among the most used primitives in cryptography. Commitments usually come in the form of commit-reveal, when at a later stage of the protocol the committee reveals the original value x they made their commitment C on. This has a great property -- a prover cannot change their committed value after revealing their commitment to the verifier, because the commitment would not hold for a new value.

\subsubsection{Vector Commitments}
Vector commitments are a relatively new primitive consisting of a vector V that as you guessed it, is filled with commitments. Simplest form of a vector commitment is a merkle tree. When proofs are based on vector commitments, the commitments guarantee that the proofs' order can't change, unless all the proofs created with the commitments are recalculated.