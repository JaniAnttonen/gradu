% !TeX root = ./Thesis.tex
\chapter{Introduction}
\label{Introduction}

Computer applications, whether they are on the public internet or on a private network, have long preferred a client-server model of communication. In this model, the client application asks things from the server, and the server responds. Applications are increasingly moving towards a more distributed, peer-to-peer (p2p) networked model, where every peer, whether it's a computer as a whole or a single process running on one, serves as the both sides of the client-server model equally. Most uses of p2p do not even get communicated to the end user. For example, the music subscription service Spotify's protocol has been designed to combine server and p2p streaming to improve scalability by decreasing the load on Spotify's servers and bandwith resources.\cite{Kreitz_undated-yp} 

The main talking points of peer-to-peer networking lately have been cryptocurrency and blockchain technologies, categorized under the roof term of distributed ledger technology. Peer-to-peer has not been really shown in the public light as anything more than a technology to work around regulation and for doing lawless activities, because before blockchain, it was popularized for its use in file sharing applications, like Bittorrent, which it still sees use for. 

Public blockchain networks need a way of synchronizing the state globally between a number of peers on a p2p network. Since the data model is sequential and all recorded history must be unchangeable, they need an algorithm to reach this total synchronization between states, a consensus algorithm. This problem is not unique to blockchains, but public blockchains have raised new issues that have sparked an ongoing development effort for new kinds of consensus algorithms.

Proof of Work is the most used consensus algorithm in public blockchains today, including Bitcoin, of in which whitepaper it was first described in 2008.\cite{Nakamoto2019-ax} New algorithms have been introduced since to battle its resource intensiveness, including Proof of Stake, which requires network nodes participating in the voting of new blocks to stake a part of their assets as a pawn. Simply this means handing the control of some of the currency owned to the consensus algorithm if the peer wants to participate in the consensus. If a voter gets labeled as malicious, faulty, or absent by a certain majority, it can get slashed, losing all or a part of the staked asset in the process. This serves as an incentive for honest co-operation, with sufficient computation resources.

One problem with Proof of Stake is that the block generation votes are not done globally, but by a selected group of peers called the validators, which vote for the contents of proposed blocks, that are generated by just one peer at a time selected as the block generator. The validators are usually selected randomly. This has generated an increasing demand for verifiable public randomness, that is pre-image resistant, meaning the output of the algorithm generating the randomness cannot be influenced beforehand. This created a motivation for an algorithm that would prevent multiple malicious actors from being selected to vote at once. A cure for this problem is called a verifiable delay function.

In 2018, two research papers were released independently with similar formalizations of a VDF.\cite{Wesolowski2018-rf}\cite{Pietrzak2018-xs} By definition, a VDF is an algorithm that requires a specified number of sequential steps to evaluate, but produces a unique output that can be efficiently and publicly verified.\cite{Boneh_undated-ml} To achieve pre-image resistance, a VDF is sequential in nature, and cannot be sped up by parallel processing. There are multiple formulations of a VDF, and not all even have a generated proof, instead using parallel processing with graphics processors to check that the calculation is sequential.\cite{Yakovenko2018-zn} This bars less powerful devices, like embedded devices, from verifying the result efficiently. Thus, generating an efficient proof that requires little time to verify is more ideal.\cite{Boneh_undated-ml}

Using a verifiable delay function, I propose a novel algorithm for producing a publicly verifiable proof of network latency and difference in computation resources between two participants in a peer-to-peer network. This proof can be used for dynamic routing to reduce latency between peers, and for making eclipse attacks\footnote{Eclipse attack means polluting the target's routing table restricting the target's access to the rest of the network, which opens up other attack possibilities regarding consensus algorithms.} harder to achieve.
