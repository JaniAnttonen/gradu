\chapter{Conclusion}
\label{Conclusion}
Since calculating a VDF is relatively easy for modern processors, a VDF over as little as a few milliseconds of time can be a valid way of measuring latency. Still, without an ASIC chip for calculating VDFs faster than any other available processor, Proof of Latency is also a measurement of processing performance. This might introduce an unfortunate barrier for entry for mobile and IoT devices. The network topology results in a gradient that is defined by geographical location and the similarity in performance.

This means closely located and similarly performant devices form strong local topologies that are bridged by their random connections to other peers and also by the connections they have to performant local peers. Highly performant devices form strong connections with each other whether they are located near each other or not, because other devices cannot compete against them in the race that is Proof of Latency, resulting in a network topology that is locally effective but global at the same time.

Proof of Latency as a peer scoring metric not only protects peers from eclipse attacks, but can also function as a way of speeding up the initial botstrapping process by bringing peers more closely together.

\section{Future Considerations}
If this system was integrated to a blockchain or a publicly verifiable source of randomness for the initial setup, the proofs could be verified by anyone against consensus. Not only this would add trust to the latency measurements, but also speed up initial bootstrapping of the P2P network. When P2P networks eventually grow larger and larger, the network bootstrapping infrastructure needs to be rethought to handle more traffic and be faster in its initialization. By getting introduced to the closest peers possible right at the start the user can experience a more performant network right from the beginning, lowering the barrier for entry by making first impressions better.

Also, I believe the work is not cryptographically as secure as it could be, and the field is progressing at a mindnumbing pace. Making sure the algorithm is VDF-agnostic would be a logical next step, since the field is still in progress of finding the best possible formulation of a VDF. Quantum computing can render all existing VDF types insufficient, and new VDF types could change the parameter logic fundamentally. The idea behind this thesis is to think of a new creative way of using verifiable delay functions by defining a protocol, and not to necessarily use the most robust cryptography available.
