% !TeX root = ./Thesis.tex
\chapter{Verifiable Delay Functions}
\label{Verifiable Delay Functions}

% TODO: Reduce vagueness, more oomph
A verifiable delay function is a function that calculates sequential calculations that cannot be significantly sped up by parallellisation or skipped, and creates a proof of the calculations that is faster to verify than the calculations are to fully re-evaluate. The computation of a VDF can be split into three distinct parts: Evaluation, proof generation, and verification. The evaluation is the hard sequential calculation from which a proof is generated.  

Verifiable delay functions are a peculiar bunch of cryptographic proofs, since they are not proving that something has happened or something has been seen, but that a certain amount of time has been spent to compute the result. This results in the fact that in many use cases the starting parameters for VDF calculation must be given by a third party or computed by a multi-party computation. This is to prevent possible precomputation --- meaning that the peer that provides a VDF proof could have computed it earlier, separately from the current transaction.

There's no known way to reduce computation costs sublinearly to the bit length of the exponent used.~\cite{Boneh2018-sm} This means that there's no algorithm-based solution to make VDF computation faster that is not related to other factors like efficiency. Despite this, there is a growing effort in developing faster hardware for VDF evaluation, especially for doing repeated modular squarings.

%TODO add an intro on VDFs from the boneh paper
\section{History}
Verifiable delay functions are based on time-lock puzzles. Like VDF's, time-lock puzzles are computational sequential puzzles that require a certain amount of time to solve.\cite{Rivest_undated-qr} Time-lock puzzles were originally created to send information into the future, which simplifies into a cryptographic time capsule. Ronald L. Rivest, Adi Shamir, and David A. Wagner classify time-lock puzzles generally under the term timed-release crypto in their 1996 paper.~\cite{Rivest_undated-qr} They describe the envisioned use cases for timed-release crypto as being the following, and they're very similar with the general concept of sending information into the future:

\begin{itemize}
	\item A bidder in an auction wants to seal his bid so that it can only be opened after the bidding period is closed 
	\item A homeowner wants to give his mortgage holder a series of encrypted mortgage payments. These might be encrypted digital cash with different decryption dates so that one payment becomes decryptable and thus usable by the bank at the beginning of each successive month
	\item An individual wants to encrypt his diaries so that they are only decryptable after fifty years.
	\item A key escrow scheme can be based on timed-release crypto so that the government can get the message keys but only after a fixed period, say one year
\end{itemize}

Verifiable delay functions fall under the same definition, but introduce a publicly verifiable proof that is much faster to verify than the puzzle was to solve. The original motivation for verifiable delay functions was to enable someone to pick off where somebody else had left when calculating a time puzzle --- to make it possible to create checkpoints in the calculation that could be trusted. At the same time, VDFs found use in blockchain applications as a way to achieve unspoofable randomness in elections and smart contract input.

\section{Use Cases}
% TODO: Explain front running, spam prevention and rate limiting use cases in LOTS more detail
Many have shown that there are more use cases for these algoritms than puzzles and random number generators. Some examples include preventing front running in P2P cryptocurrency exchanges, spam prevention and rate limiting~\cite{noauthor_undated-hk} Almost all use cases are based on the property that with a new unique input, and a difficulty requirement, there is no easy way to speed up the calculation.

In the front-running use case, this property can be used to restrict front-running in both centralized and decentralized exchanges.~\cite{Khalil2019-sl} Front-running is a term used in both stock trading and cryptocurrency trading which means using inside knowledge of a future transaction to trade the asset with a better price or deny the other transaction from happening.~\cite{Robinson2020-ve} The issue is pronounced in trustless P2P networks like the Ethereum blockchain, where pending transactions are for all to see and can be overtook by giving the network validators a bigger reward, for example.~\cite{Mitchell2020-hn} In a centralized exchange, preventing front-running with a VDF means that the exchange waits for a specified time before it starts the fulfilling the trade. The VDF serves as a receipt for the order taker that there was no reordering and the take orders were processed in a FIFO\footnote{First in, first out} fashion.~\cite{Cline2020-wb} In a decentralized exchange the same holds, if there exists only one peer that can fulfill the order. The peer then functions exactly like the centralized exchange mentioned before.

Spam prevention and rate limiting in the context of VDFs mean roughly the same thing. This is because spam prevention with VDFs is done with rate limiting. If a network application requires peers to perform some sort of Proof-of-Work in a form of a VDF, by defining the difficulty parameter T they can set a time boundary for subsequent requests, also called a rate limit. If all the peers need to perform a challenge to request resources from the requestee, a performance-based limit is created for the time between each individual request, thus limiting spam.

\section{Variations}
% TODO: Add a footnote for groups of unknown order, add groups of unknown order to cryptography chapter? Describe Wesolowski's and the other's differences
There are multiple variations on the security principles used, since a VDF can use any group of unknown order as a basis for its unpredictability. Known solutions use RSA, elliptic curves and class groups as their cryptographic basis.

% TODO ADD MATH, DEFINITIONS, Explain how VDF works!

\section{Similar Constructs}
\subsection{Proto-VDF}
A VDF can only be calculated sequentially, but even without a proof there is a possibility to make the verification faster through parallellism. A non-verifiable delay function, or time-lock puzzle in short, can be still verified faster than the calculation, because there is no sequential requirement after the puzzle has been calculated, enabling to use multiple CPU cores or highly parallel graphics processing units for verifying the puzzle, like in Solana.~\cite{Yakovenko2018-zn} One could also argue that all blockchains and some random beacons form multi-party calculated VDFs. Solana's Proof of History can be described as a proto-VDF, since it was invented before the term VDF was coined, but with similar quarantees.

\subsection{Classic Slow Functions}
Since VDF's idea is that a hard calculation can be verified faster than to be evaluated, any calculation of which inverse is harder is a candidate for a VDF-type construct. One example of these asymmetric calculations is Sloth.~\cite{Boneh2018} Sloth doesn't include a proof and is not asymptotically verifiable, thus not filling the definition of a VDF per se.\footnote{Asymptotic, meaning that there is a maximum verification time and the verification can't scale beyond that point.} The evaluation of Sloth is calculated with repeated cubic roots, and is verified with repeated cubings, with cubic roots being harder to compute than the cubings.

\section{Hardware Developments}
VDF applications can be made faster with hardware, and it has been estimated that with an ASIC\footnote{Application-Specific Integrated Circuit. A purpose-built chip for a single algorithm.} chip a VDF can be evaluated more than ten times faster than with a GPU.~\cite{Stanford_Video2020-ap}
The three different parts of a VDF calculation are different in terms of the hardware that can be utilized to make them faster. The evaluation part currently has no de facto hardware to make it faster, but the ASIC and FPGA developments are the ones pushing this part forward. Proving can be made faster with GPUs, whilst verification benefits from fast general computation, thus CPUs.\cite{Protocol_Labs_Kelly_Olson2020-au} The chip developments for evaluation also help calculation of zero-knowledge proofs, since they also use repeated squarings for proof generation, thus benefiting cryptography at large.
If or when hardware specifically optimized for sequential squarings is commercialized, VDFs can become much more mainstream, and suffer less from computational differences, thus requiring less trust between the calculating parties. It's a race against time, since if an attacker put a considerable amount of resources in the development of such a chip themselves, they could potentially compromise the security of some blockchains, due to an assumption called weak subjectivity.~\cite{noauthor_2018-ro} Weak subjectivity means favoring a blockchain with the most blocks in it, rather than focusing on a majority vote.~\cite{Buterin2019-jz} By creating blocks faster than the majority of the network, one could attack proof of stake systems relying on weak subjectivity with a proprietary chip.

Besides the development of an ASIC driven by vdfresearch.org~\cite{noauthor_undated-hk}, there's been development on CPU instructions by Intel, aiming to help the specific operation of modular exponentiation, which is used not only in VDFs, but also in classical RSA, DSA, and DH algorithms, not to mention homomorphic encryption.~\cite{Drucker2019-cx} 
